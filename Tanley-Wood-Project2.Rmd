---
title: "Tanley-Wood-Project2"
author: "Jordan Tanley and Jonathan Wood"
date: '2022-07-05'
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Here's the new file - idk what happened but my R malfunctioned for some reason and I had to make a new one. 

# Introduction - Jonathan



# Data - Jordan

```{r, include=FALSE}
library(readr)
library(tidyverse)
library(ggplot2)
library(knitr)
library(gridExtra)
library(caret)
```

In order to read in the data using a relative path, be sure to have the data file saved in your working directory.  

```{r}
# read in the data
news <- read_csv("OnlineNewsPopularity/OnlineNewsPopularity.csv")
```

```{r} 
#DONT FORGET TO DROP THIS VARIABLE WHEN DOING RANDOM FOREST AND BOOSTED TREE
news$weekday <- ifelse(news$weekday_is_friday == 1, "Friday",
                       ifelse(news$weekday_is_monday == 1, "Monday",
                              ifelse(news$weekday_is_tuesday == 1, "Tuesday",
                                     ifelse(news$weekday_is_wednesday == 1, "Wednesday",
                                            ifelse(news$weekday_is_thursday == 1, "Thursday",
                                                   ifelse(news$weekday_is_saturday == 1, "Saturday", 
                                                          "Sunday"))))))
```


Next, let's subset the data so that we can only look at the data channel of interest.

```{r}
SocialMedia <- news %>% 
                as_tibble() %>% 
                filter(data_channel_is_socmed == 1) %>% 
                select(-c(url, timedelta, starts_with("data_channel")))
head(SocialMedia)
```


# Summarizations - Both (3 plots each)

```{r}
# Contingency table of frequencies for days of the week
kable(table(SocialMedia$weekday), 
      col.names = c("Weekday", "Frequency"), 
      caption = "Contingency table of frequencies for days of the week")

# Numerical Summary of Shares
SocialMedia %>% summarise(Minimum = min(shares), 
                          Q1 = quantile(shares, prob = 0.25), 
                          Average = mean(shares), 
                          Median = median(shares), 
                          Q3 = quantile(shares, prob = 0.75), 
                          Maximum = max(shares)) %>% 
                kable(caption = "Numerical Summary of Shares")

# Numerical Summary of Number of words in the content
SocialMedia %>% summarise(Minimum = min(n_tokens_content), 
                          Q1 = quantile(n_tokens_content, prob = 0.25), 
                          Average = mean(n_tokens_content), 
                          Median = median(n_tokens_content), 
                          Q3 = quantile(n_tokens_content, prob = 0.75), 
                          Maximum = max(n_tokens_content)) %>% 
                kable(caption = "Numerical Summary of Number of words in the content")

# Numerical Summary of Number of words in the content for the upper quantile of Shares
SocialMedia %>% filter(shares > quantile(shares, prob = 0.75)) %>%
                summarise(Minimum = min(n_tokens_content), 
                          Q1 = quantile(n_tokens_content, prob = 0.25), 
                          Average = mean(n_tokens_content), 
                          Median = median(n_tokens_content), 
                          Q3 = quantile(n_tokens_content, prob = 0.75), 
                          Maximum = max(n_tokens_content)) %>% 
                kable(caption = "Numerical Summary of Number of words in the content for the upper quantile of Shares")

```


```{r}
# Boxplot of Shares for Each Weekday
ggplot(SocialMedia, aes(x = weekday, y = shares)) + 
          geom_boxplot(fill = "grey") + 
          labs(x = "Weekday", title = "Boxplot of Shares for Each Weekday", y = "Shares") + 
          theme_classic()

# Scatterplot of Number of words in the content vs Shares
ggplot(SocialMedia, aes(x = n_tokens_content, y = shares)) + 
          geom_point(color = "grey") +
          labs(x = "Number of words in the content", y = "Shares", 
               title = "Scatterplot of Number of words in the content vs Shares") +
          theme_classic()

# Scatterplot of Number of words in the title vs Shares
ggplot(SocialMedia, aes(x = n_tokens_title, y = shares)) + 
          geom_point(color = "grey") +
          labs(x = "Number of words in the title", y = "Shares", 
               title = "Scatterplot of Number of words in the title vs Shares") +
          theme_classic()

```






```{r}
SocialMedia <- subset(SocialMedia, select = -c(weekday))
```


# Modeling

## Splitting the Data

First, let's split up the data into a testing set and a training set using the proportions: 70% training and 30% testing.

```{r}
set.seed(9876)
# Split the data into a training and test set (70/30 split)
# indices
train <- sample(1:nrow(SocialMedia), size = nrow(SocialMedia)*.70)
test <- setdiff(1:nrow(SocialMedia), train)
# trainiing and testing subsets
Training <- SocialMedia[train, ]
Testing <- SocialMedia[test, ]
```

## Linear Models

INSERT EXPLANATION HERE! (note to myself - not yelling at you! lol)

Linear Model #1: - Jordan

```{r, warning=FALSE}
fit1 <- train(shares ~ . , data = Training, method = "lm",
              preProcess = c("center", "scale"), 
              trControl = trainControl(method = "cv", number = 5))
```

Linear Model #2: - Jonathan

```{r}

```


## Random Forest - Jordan

INSERT EXPLANATION HERE! (note to myself - not yelling at you! lol)

```{r}
ranfor <- train(shares ~ ., data = Training, method = "rf", preProcess = c("center", "scale"),
                trControl = trainControl(method = "cv", number = 5), 
                tuneGrid = expand.grid(mtry = c(1:round(ncol(Training)/3))))

ranfor
```



## Boosted Tree - Jonathan







# Comparison - Jordan

```{r, warning=FALSE}

predRF <- predict(ranfor, newdata = Testing)
RF <- postResample(predRF, Testing$shares)

predlm1 <- predict(fit1, newdata = Testing)
LM <- postResample(predlm1, Testing$shares)

# NEEDS TO BE REPEATED FOR OTHER TWO MODELS - I'll do this later!

dat <- data.frame(rbind(t(data.frame(LM)), t(data.frame(RF))))
df <- as_tibble(rownames_to_column(dat, "models"))

best <- df %>% filter(RMSE == min(RMSE)) %>% select(models)

paste("The Best fitting model according to RMSE is", best$models, sep = " ")

```



# Automation - Jonathan






